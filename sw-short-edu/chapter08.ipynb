{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 08 웹 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 웹 데이터 자동 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML 소스 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\t\t\t\t\t\t\t\t\t\t\t\t# requests 모듈 불러오기\n",
    "res = requests.get(\"http://www.naver.com\", verify = False)\t# GET 방식으로 네이버 홈페이지 가져오기\n",
    "print(res.text)\t\t\t\t\t\t\t\t\t\t\t\t# 한글로 내용 출력\n",
    "#print(res.content)\t\t\t\t\t\t\t\t\t\t\t# uni-code로 내용 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"code\" : \"005930\"}\n",
    "res = requests.get(\"https://finance.naver.com/item/sise.nhn\", params=parameters, verify = False)\n",
    "print(res.url)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(\"https://finance.naver.com/item/sise.nhn?code=005930\", verify = False)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = requests.post(\"https://finance.naver.com/item/sise.nhn = 005930\", verify = False)\n",
    "res = requests.post(\"https://finance.naver.com/item/sise.nhn?code =005930\", verify = False)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post(\"https://naver.com/\", verify = False)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML 소스를 데이터로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\t\t\t# BeautifulSoup 설치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\t\t\t# BeautifulSoup 모듈 불러오기\n",
    "\n",
    "# html_txt 변수에 HTML 소스와 텍스트 입력\n",
    "html_txt = \"<p class='weather' id='tw'>오늘의 날씨</p>  <h1> 한때 소나기가 내리겠습니다.</h1>\"\n",
    "\n",
    "soup = BeautifulSoup(html_txt,\"html.parser\")\t \t# 파싱하기, 분석 가능한 데이터 형태로 변환\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = soup.find(\"p\")\t\t# p 태그를 찾아 tag에 저장\n",
    "\n",
    "print(tag)\t\t\t\t\t# tag 출력\n",
    "print(tag.name)\t\t\t\t# tag명 출력\n",
    "print( tag.attrs )\t\t\t# tag 속성 출력\n",
    "print(tag.attrs[\"class\"])\t# tag 속성 중 class만 출력\n",
    "print(tag.attrs[\"id\"])\t\t# tag 속성 중 id만 출력\n",
    "print(tag.text)\t\t\t\t# tag 내 텍스트 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### html 소스를 분석용 데이터로 파싱(변환)하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\t\t\t# BeautifulSoup 모듈 불러오기\n",
    "# html 소스 생성하기\n",
    "html_txt = \"\"\"\n",
    "<html>\n",
    "    <head><title>BS page</title></head>\n",
    "    <body>\n",
    "        <h1 class=\"portal_cls\">검색포털</h1>\n",
    "        <p>\n",
    "            <a href=\"http://www.daum.net\">다음 바로가기</a><br>\n",
    "            <ul>\n",
    "                <li>장미 축제\n",
    "                    <a href=\"http://www.daum.net/rose\">장미 축제 바로가기</a><br>\n",
    "                <li>불꽃 축제\n",
    "                    <a href=\"http://www.daum.net/fireworks\">불꽃 축제 바로가기</a><br>\n",
    "            </ul>\n",
    "            <a href=\"http://www.naver.com\">네이버 바로가기</a>\n",
    "        </p>\n",
    "        <a href=\"http://www.google.com\" class=\"alink_cls\">구글</a>\n",
    "        <p class=\"footage_cls\" id=\"company\">2021, ABC Company </p>\n",
    "        <p class=\"footage_cls\" id=\"addr\">Korea</p>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_txt, \"html.parser\")\t\t# 파싱하기, 분석 가능한 데이터 형태로 변환\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = soup.select_one(\"h1\")\t\t\t# <h1> </h1> 태그 추출\n",
    "print(tag.text)\t\t\t\t\t# tag 안에 있는 텍스트만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select() 함수로 태그를 추출하면 list형 자료로 반환되기 때문에 반복문을 활용해 데이터를 하나씩 가져와야 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = soup.select(\"h1\")\t\t# <h1> ~ </h1> 태그 모두 찾기\n",
    "for tag in tag_list:\t\t\t\t# tag_list 내 데이터를 하나씩 읽어오기\n",
    "    print(tag.text)\t\t\t\t# 텍스트만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag_list = soup.select(\"body p > a\")\t\t# <body><p> 태그 하위의 <a> 태그 추출\n",
    "for tag in tag_list:\t\t\t\t\t\t# tag_list 내 데이터를 하나씩 읽어오기\n",
    "    print(tag.text)\t\t\t\t\t\t\t# 텍스트만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = soup.select(\"body p a\")\t\t\t# <body><p> 태그 하위의 <a> 태그 추출하고, 그 하위의 모든 태그도 추출\n",
    "for tag in tag_list:\t\t\t\t\t\t# tag_list 내 데이터를 하나씩 읽어오기\n",
    "    print(tag.text)\t\t\t\t\t\t\t# 텍스트만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = soup.select(\".footage_cls\")\t\t# footage_cls 클래스 추출\n",
    "for tag in tag_list:\t\t\t\t\t\t# tag_list 내 데이터를 하나씩 읽어오기\n",
    "    print(tag.text)\t\t\t\t\t\t\t# 텍스트만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = soup.select(\"#company\")\t\t\t# id가 company인 태그 추출\n",
    "for tag in tag_list:\t\t\t\t\t\t# tag_list 내 데이터를 하나씩 읽어오기\n",
    "    print (tag.text)\t\t\t\t\t\t# 텍스트만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = soup.select(\"a[href]\")\t\t\t# a 태그 중 속성 값 href 를 갖는 태그 추출\n",
    "for tag in tag_list:\t\t\t\t\t\t# tag_list 내 데이터를 하나씩 읽어오기\n",
    "    print(tag.text, tag.attrs[\"href\"])\t\t# 텍스트와 URL 출력"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 서점 베스트셀러 정보 가져오기\n",
    "교보문고 베스트셀러 웹 페이지인 http://www.kyobobook.co.kr/bestSellerNew/bestseller.laf 에 접속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "import requests\t\t\t\t\t\t\t\t\t# 웹 리소스를 가져오는 모듈\n",
    "from bs4 import BeautifulSoup as bs\t\t\t\t#데이터 변환(파싱) 및 원하는 태그 추출 시 사용\n",
    "import pandas as pd\t\t\t\t\t\t\t\t#데이터 프레임\n",
    "\n",
    "# 교보문고의 월간 베스트셀러 웹 페이지 가져오기\n",
    "res = requests.get(\"http://www.kyobobook.co.kr/bestSellerNew/bestseller.laf?range = \\\n",
    "        1&kind=2&orderClick = DAB&mallGb=KOR&linkClass=A\")\n",
    "book = bs(html, \"html.parser\")\t\t\t\t\t# HTML 파싱\n",
    "#print(book)\n",
    "\n",
    "# 도서 상세 페이지 주소 추출하기\n",
    "book_list = []\t\t\t\t\t\t\t\t\t# book_list 리스트 변수 만들기\n",
    "for book_detail in book.select(\"div.detail\"):\t# book에서 class=detail 태그 가져오기\n",
    "    book_urls = book_detail.select_one(\"div.title > a\").attrs[\"href\"]   # 상세 주소를 book_urls에 저장\n",
    "    book_list.append(book_urls)\t\t\t\t\t# book_list 변수에 주소를 하나씩 추가\n",
    "    #print(book_list)\n",
    "\n",
    "# 도서별 상세 데이터 추출하기\n",
    "best = pd.DataFrame(columns=[\"도서\",\"저자\",\"가격\",\"url\"])\t\t# 저장할 데이터프레임 만들기\n",
    "for index, book_url in enumerate(book_list):\t\t\t\t# 도서 상세 페이지를 하나씩 반환\n",
    "    res = requests.get(book_url)\t\t\t\t\t\t\t# 도서 상세 페이지 리소스 가져오기\n",
    "    html = res.content\n",
    "    best_book = bs(html, \"html.parser\", from_encoding = \"cp949\")\t\t# HTML 파싱\n",
    "    title = best_book.select_one(\"h1.title strong\").text.strip()\t\t# 도서명 추출\n",
    "    author = best_book.select_one(\"span.name a\").text.strip()\t\t\t# 저자명 추출\n",
    "    price = best_book.select_one(\"span.sell_price strong\").text.strip()\t# 가격 추출    \n",
    "    best.loc[index+1] = (title, author, price, book_url)\t\t\t\t# 데이터 프레임에 저장\n",
    "#best.head()\n",
    "\n",
    "# 엑셀 파일로 저장하기\n",
    "best.to_excel(\"chapter08/bestseller.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 웹 브라우저 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 본인의 chrome 정보를 확인한 후\n",
    "- 크롬 드라이버 페이지(https://chromedriver.chromium.org/downloads) 에 접속해서 크롬 브라우저의 버전과 동일한 웹 드라이버를 다운로드\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 로드 및 HTML 소스 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\t\t\t\t\t\t# selenium 모듈 불러오기\n",
    "from selenium import webdriver\t\t# webdriver 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.naver.com\"\t\t\t\t# 네이버 URL을 URL 변수에 저장\n",
    "driver = webdriver.Chrome(\"chromedriver\")\t# driver 객체 생성 \n",
    "driver.get(URL)\t\t\t\t\t\t\t\t# URL에 저장된 주소를 크롬에서 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(driver.current_url)\t\t\t\t# 현재 URL 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML 소스 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrom 으로 Naver 자동 접속하기\n",
    "import selenium\t\t\t\t\t\t\t\t# selenium 모듈 불러오기\n",
    "from bs4 import BeautifulSoup\t\t\t\t# BeautifulSoup 모듈 불러오기\n",
    "from selenium import webdriver\t\t\t\t# webdriver 모듈 불러오기\n",
    "URL = \"https://www.naver.com\"\t\t\t\t# 네이버 URL을 URL 변수에 저장\n",
    "driver = webdriver.Chrome(\"chromedriver\")\t# driver 객체 생성 \n",
    "driver.get(URL)\t\t\t\t\t\t\t\t# URL에 저장된 주소를 크롬에서 열기\n",
    "\n",
    "# HTML 소스 파싱하기\n",
    "html = driver.page_source  \t\t\t\t\t# HTML 소스 가져오기\n",
    "soup = BeautifulSoup(html, \"html.parser\")\t# 데이터 변환(파싱)\n",
    "\n",
    "# 텍스트 출력하기\n",
    "tag_list = soup.select(\"body p\")\t\t\t# <body> 내 <p> 태그 추출\n",
    "for tag in tag_list:\t\t\t\t\t\t# tag_list 내 데이터를 하나씩 읽어오기\n",
    "    print(tag.text)\t\t\t\t\t\t\t# 텍스트만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 브라우저 제어하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Naver 로그인] 버튼 자동으로 클릭하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\t\t\t\t\t\t\t\t\t\t\t\t\t# selenium 모듈 불러오기\n",
    "from selenium import webdriver\t\t\t\t\t\t\t\t\t# webdriver 모듈 불러오기\n",
    "from selenium.webdriver.common.by import By\t\t\t\t\t\t# selenium의 by 클래스 불러오기\n",
    "URL = \"https://www.naver.com\"\t\t\t\t\t\t\t\t\t# 네이버 URL을 URL 변수에 저장\n",
    "driver = webdriver.Chrome(\"chromedriver\")\t\t\t\t\t\t# driver 객체 생성 \n",
    "driver.get(URL)\t\t\t\t\t\t\t\t\t\t\t\t\t# URL에 저장된 주소를 크롬에서 열기\n",
    "btn = driver.find_element(By.XPATH, '//*[@id=\"account\"]/a')\t\t# 네이버 로그인 버튼 선택\n",
    "btn.click()\t\t\t\t\t\t\t\t\t\t\t\t\t\t# 로그인 버튼 클릭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버에서 방탄소년단 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\t\t\t\t\t\t\t\t\t\t\t\t\t# selenium 모듈 불러오기\n",
    "from selenium import webdriver\t\t\t\t\t\t\t\t\t# webdriver 모듈 불러오기\n",
    "from selenium.webdriver.common.by import By\t\t\t\t\t\t# selenium의 by 클래스 불러오기\n",
    "URL = \"https://www.naver.com\"\t\t\t\t\t\t\t\t\t# 네이버 URL을 URL 변수에 저장\n",
    "driver = webdriver.Chrome(\"chromedriver\")\t\t\t\t\t\t# driver 객체 생성 \n",
    "driver.get(URL)\t\t\t\t\t\t\t\t\t\t\t\t\t# URL에 저장된 주소를 크롬에서 열기\n",
    "input_tag = driver.find_element(By.CSS_SELECTOR, \"#query\")\t\t# 검색창으로 이동하여\n",
    "input_tag.send_keys(\"방탄소년단\")\t\t\t\t\t\t\t\t# 검색창에 문자 입력\n",
    "input_tag.send_keys(\"\\n\")\t\t\t\t\t\t\t\t\t\t# Enter 키 실행\n",
    "driver.implicitly_wait(3)\t\t\t\t\t\t\t\t\t\t# 최대 3초간 대기(3초가 지나면 다음 코드 수행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# 웹 드라이버 종료"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
